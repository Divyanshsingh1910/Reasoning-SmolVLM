{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9571172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting docopt>=0.6.2 (from num2words)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13781 sha256=ed70be4043316e44e524d92ef4e12405730c1670576965922996e3b16d6fac59\n",
      "  Stored in directory: /home/divyansh/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.14\n"
     ]
    }
   ],
   "source": [
    "! pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb0e24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Dict, List, Union, Any\n",
    "import re\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c990852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path: str) -> List[Dict]:\n",
    "    \n",
    "    with open(dataset_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "def is_numeric(text: str) -> bool:\n",
    "   \n",
    "    try:\n",
    "        cleaned_text = text.replace(',', '')\n",
    "        float(cleaned_text)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def normalize_answer(answer: str) -> str:\n",
    "    answer = answer.lower()\n",
    "    answer = re.sub(r'\\b(a|an|the)\\b', ' ', answer)\n",
    "    answer = re.sub(r'[^\\w\\s.]', '', answer)\n",
    "    answer = re.sub(r'(?<!\\d)\\.|\\.(?!\\d)', '', answer)\n",
    "    answer = re.sub(r'\\s+', ' ', answer).strip()\n",
    "\n",
    "    return answer\n",
    "\n",
    "def check_answer_correctness(pred: str, label: str) -> bool:\n",
    "    pred_normalized = normalize_answer(pred)\n",
    "    label_normalized = normalize_answer(label)\n",
    "\n",
    "    if label_normalized in pred_normalized:\n",
    "        return True\n",
    "\n",
    "    is_list = (label.startswith('[') and label.endswith(']'))\n",
    "    elements = []\n",
    "    if is_list:\n",
    "        list_content = label[1:-1].strip()\n",
    "        if list_content:\n",
    "            elements = [e.strip() for e in list_content.split(',')]\n",
    "        normalized_elements = [normalize_answer(e) for e in elements]\n",
    "        all_elements_present = all(elem in pred_normalized for elem in normalized_elements)\n",
    "        if all_elements_present:\n",
    "            return True\n",
    "\n",
    "    label_is_numeric = is_numeric(label_normalized)\n",
    "    if label_is_numeric:\n",
    "        pred_tokens = pred.split()\n",
    "        for token in pred_tokens:\n",
    "            token = normalize_answer(token)\n",
    "            if is_numeric(token):\n",
    "                try:\n",
    "                    pred_val = float(token.replace(',', ''))\n",
    "                    label_val = float(label_normalized.replace(',', ''))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                if abs(label_val) < 1e-10:\n",
    "                    if abs(pred_val - label_val) < 1e-10:\n",
    "                        return True\n",
    "                    else:\n",
    "                        continue\n",
    "                rel_error = abs(pred_val - label_val) / abs(label_val)\n",
    "                if rel_error <= 0.05:\n",
    "                    return True\n",
    "            else:\n",
    "              num_as_word = num2words(label).lower()\n",
    "              if token == num_as_word:\n",
    "                  return True\n",
    "\n",
    "              try:\n",
    "                  text_as_num = float(token)\n",
    "                  if label < 1e-10:\n",
    "                      return abs(label - text_as_num) < 1e-10\n",
    "\n",
    "                  rel_error = abs(label - text_as_num) / abs(label)\n",
    "                  return rel_error <= 0.05  # 5% tolerance\n",
    "              except (ValueError, TypeError):\n",
    "                  continue\n",
    "        return False\n",
    "\n",
    "    label_words = label.split()\n",
    "    pred_words = pred.split()\n",
    "    for i,words in pred_words:\n",
    "        pred_words[i] = normalize_answer(words)\n",
    "\n",
    "    current_pos = 0\n",
    "    for word in label_words:\n",
    "        word = normalize_answer(word)\n",
    "        try:\n",
    "            current_pos = pred_words.index(word, current_pos) + 1\n",
    "        except ValueError:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class ChartQAEvaluator:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator.\n",
    "\n",
    "        Args:\n",
    "            model: The VLM model to evaluate\n",
    "            image_dir: Directory containing chart images\n",
    "        \"\"\"\n",
    "\n",
    "    def process_single_example(self, example: Dict) -> Dict[str, Any]:\n",
    "\n",
    "        try:\n",
    "            prediction = example['output']\n",
    "\n",
    "            is_correct = check_answer_correctness(prediction, example[\"label\"])\n",
    "            print(\"\\n``````````````````````````````````````````````````````````\")\n",
    "            print(f\"Query: {example['query']}\")\n",
    "            print(f\"label: {example['label']}\")\n",
    "            print(f\"Prediction: {prediction}\")\n",
    "            print(f\"Truth: {is_correct}\")\n",
    "            print(\"``````````````````````````````````````````````````````````\")\n",
    "\n",
    "\n",
    "            return {\n",
    "                \"example\": example,\n",
    "                \"prediction\": prediction,\n",
    "                \"is_correct\": is_correct\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing : {e}\")\n",
    "            return {\n",
    "                \"example\": example,\n",
    "                \"prediction\": \"\",\n",
    "                \"is_correct\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def evaluate_dataset(self, dataset: List[Dict]) -> Dict[str, Any]:\n",
    "        results = []\n",
    "        numeric_results = []\n",
    "        non_numeric_results = []\n",
    "\n",
    "        for example in tqdm(dataset, desc=\"Evaluating\"):\n",
    "            result = self.process_single_example(example)\n",
    "            results.append(result)\n",
    "\n",
    "            if is_numeric(example[\"label\"]):\n",
    "                numeric_results.append(result[\"is_correct\"])\n",
    "            else:\n",
    "                non_numeric_results.append(result[\"is_correct\"])\n",
    "\n",
    "\n",
    "        overall_accuracy = np.mean([r[\"is_correct\"] for r in results])\n",
    "\n",
    "        numeric_accuracy = np.mean(numeric_results) if numeric_results else 0\n",
    "        non_numeric_accuracy = np.mean(non_numeric_results) if non_numeric_results else 0\n",
    "\n",
    "        return {\n",
    "            \"overall_accuracy\": float(overall_accuracy),\n",
    "            \"numeric_accuracy\": float(numeric_accuracy),\n",
    "            \"non_numeric_accuracy\": float(non_numeric_accuracy),\n",
    "            \"num_examples\": len(dataset),\n",
    "            \"num_numeric\": len(numeric_results),\n",
    "            \"num_non_numeric\": len(non_numeric_results),\n",
    "            \"detailed_results\": results\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c595078",
   "metadata": {},
   "source": [
    "### Assign the paths in the cell below\n",
    "- `input_dir`: Directory containing model responses in following format:\n",
    "```json\n",
    "    {\n",
    "        \"imgname\": \"multi_col_100294.png\",\n",
    "        \"query\": \"What is the average of all the dark blue bars?\",\n",
    "        \"label\": \"22.33\",\n",
    "        \"output\": \"23.67.\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2126f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    input_dir = \"results\"\n",
    "    output_dir = \"eval_results\"\n",
    "    for files in os.listdir(input_dir):\n",
    "        output_path = output_dir + \"/\"+files + \"_eval_results.json\"\n",
    "        model_name = input\n",
    "\n",
    "        dataset = load_dataset(input_dir + \"/\"+files)\n",
    "\n",
    "        evaluator = ChartQAEvaluator()\n",
    "\n",
    "        results = evaluator.evaluate_dataset(dataset)\n",
    "\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "        print(\"\\nEvaluation Results:\")\n",
    "        print(f\"Model Name: {model_name}\")\n",
    "        print(f\"Overall Accuracy: {results['overall_accuracy']:.4f}\")\n",
    "        print(f\"Numeric Accuracy: {results['numeric_accuracy']:.4f} ({results['num_numeric']} examples)\")\n",
    "        print(f\"Non-Numeric Accuracy: {results['non_numeric_accuracy']:.4f} ({results['num_non_numeric']} examples)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
