{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from transformers.image_utils import load_image\n",
    "from datasets import features, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22dd9c9",
   "metadata": {},
   "source": [
    "### Use the checkpoint path of desired model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"checkpoints/SFT_256M_smolcot_mini_3k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e90d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"CPU\"\n",
    "DEVICE\n",
    "\n",
    "from accelerate import PartialState\n",
    "device_string = PartialState().process_index\n",
    "\n",
    "\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16, device_map={'':device_string}\n",
    ")\n",
    "\n",
    "DEVICE = model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da311f7",
   "metadata": {},
   "source": [
    "### Either use any data or any individual example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58358ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = Dataset.load_from_disk(\"../data/eval_smolcot_hf\")\n",
    "# len(data)\n",
    "\n",
    "\n",
    "qs = \"How many people are in the image?\"\n",
    "image = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53969a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": f\"{qs}\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "with torch.no_grad():\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    \n",
    "    generated_ids = model.generate(**inputs\n",
    "    # generated_ids = model.generate(**inputs\n",
    "                                   , max_new_tokens = 256\n",
    "                                   )\n",
    "    generated_texts = processor.batch_decode(\n",
    "        generated_ids,\n",
    "        skip_special_tokens=True,\n",
    "    \n",
    "    )\n",
    "\n",
    "print(\"----------------\\nOutput:\\n----------------\")\n",
    "print(generated_texts[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
